{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ef5cab",
   "metadata": {},
   "source": [
    "## SVM Text Data - Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04160e77",
   "metadata": {},
   "source": [
    "## Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e51404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read csv files as df\n",
    "df1 = pd.read_csv('../data/cleaned_goldman_sachs_tweets.csv', on_bad_lines='skip')\n",
    "df2 = pd.read_csv('../data/cleaned_apple_tweets.csv', on_bad_lines='skip')\n",
    "df3 = pd.read_csv('../data/cleaned_home_depot_tweets.csv', on_bad_lines='skip')\n",
    "\n",
    "# Print the head of each df\n",
    "print(df1.head())\n",
    "print(df2.head())\n",
    "print(df3.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5590bf5",
   "metadata": {},
   "source": [
    "## Data Cleaning and cocat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b02300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X\n",
    "# Push column name of df1 into values\n",
    "df1.loc[-1] = df1.columns.values\n",
    "df1.sort_index(inplace=True)\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "df1.rename(columns={\"goldman\": \"tweets\"}, inplace=True) #rename column\n",
    "df1['company'] = 'goldman_sachs' #add new column with company label\n",
    "print(df1)\n",
    "\n",
    "# Do the same for df2\n",
    "df2.loc[-1] = df2.columns.values\n",
    "df2.sort_index(inplace=True)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2.rename(columns={\"email\": \"tweets\"}, inplace=True) #rename column\n",
    "df2['company'] = 'apple' #add new column with company label\n",
    "print(df2)\n",
    "\n",
    "# Do the same for df3\n",
    "df3.loc[-1] = df3.columns.values\n",
    "df3.sort_index(inplace=True)\n",
    "df3.reset_index(drop=True, inplace=True)\n",
    "df3.rename(columns={\"koch\": \"tweets\"}, inplace=True) #rename column\n",
    "df3['company'] = 'home_depot' #add new column with company label\n",
    "print(df3)\n",
    "\n",
    "# Concat dataframes\n",
    "df = pd.concat([df1, df2, df3])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e133b1e",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine class distribution\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# Visualize class distribution\n",
    "df['company'] = pd.factorize(df.company, sort=True)[0]\n",
    "\n",
    "fig, ax1 = plt.subplots(ncols=1, figsize=(10,6))\n",
    "\n",
    "df['company'].value_counts().plot(kind='bar',\n",
    "                            rot=0,\n",
    "                            fontsize=15,\n",
    "                            ax=ax1)\n",
    "ax1.set_title('Distribution of Tweets', fontsize=20)\n",
    "ax1.set_xlabel('Tweet Label', fontsize=15)\n",
    "ax1.set_ylabel('Number of Words', fontsize=15)\n",
    "\n",
    "# save picture\n",
    "fig1 = ax1.get_figure()\n",
    "fig1.savefig(\"../501-project-website/images/SVM_tweet_labels_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff66f75",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2592cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline model\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def generate_label_data(class_labels, weights,N=10000):\n",
    "    y=random.choices(class_labels, weights = weights, k = N)\n",
    "    print(\"-----GENERATING DATA-----\")\n",
    "    print(\"unique entries:\",Counter(y).keys())  \n",
    "    print(\"count of labels:\",Counter(y).values()) # counts the elements' frequency\n",
    "    print(\"probability of labels:\",np.fromiter(Counter(y).values(), dtype=float)/len(y)) # counts the elements' frequency\n",
    "    return y\n",
    "\n",
    "## Generate random classifier\n",
    "def random_classifier(y_data):\n",
    "    ypred=[];\n",
    "    max_label=np.max(y_data); #print(max_label)\n",
    "    for i in range(0,len(y_data)):\n",
    "        ypred.append(int(np.floor((max_label+1)*np.random.uniform(0,1))))\n",
    "\n",
    "    print(\"-----RANDOM CLASSIFIER-----\")\n",
    "    print(\"count of prediction:\",Counter(ypred).values()) # counts the elements' frequency\n",
    "    print(\"probability of prediction:\",np.fromiter(Counter(ypred).values(), dtype=float)/len(y_data)) # counts the elements' frequency\n",
    "    print(\"accuracy\",accuracy_score(y_data, ypred))\n",
    "    print(\"percision, recall, fscore,\",precision_recall_fscore_support(y_data, ypred))\n",
    "\n",
    "# Random classifier\n",
    "print(\"\\MULTI-CLASS: UNIFORM LOAD\")\n",
    "y=generate_label_data([0,1,2],[1/3, 1/3, 1/3],10000)\n",
    "random_classifier(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d870a",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X\n",
    "corpus=df[\"tweets\"].to_list()\n",
    "# Initialize count vectorizer\n",
    "\n",
    "# Ignore terms that appear in less than 1% of the documents\n",
    "vectorizer=CountVectorizer(min_df=0.01)   \n",
    "\n",
    "# Run count vectorizer on corpus \n",
    "Xs  =  vectorizer.fit_transform(corpus)   \n",
    "X=np.array(Xs.todense())\n",
    "\n",
    "# Convert to one-hot vectors\n",
    "maxs=np.max(X,axis=0)\n",
    "X=np.ceil(X/maxs)\n",
    "\n",
    "# Double check\n",
    "print(X.shape)\n",
    "print(\"DATA POINT-0:\",X[0,0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c5749",
   "metadata": {},
   "source": [
    "## Prepare data for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88026456",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET X AND Y\n",
    "\n",
    "# y: CONVERT FROM STRING LABELS TO INTEGERS \n",
    "labels=[]; \n",
    "y=[]\n",
    "for label in df[\"company\"]:\n",
    "    if label not in labels:\n",
    "        labels.append(label)\n",
    "        print(\"index =\",len(labels)-1,\": label =\",label)\n",
    "    for i in range(0,len(labels)):\n",
    "        if(label==labels[i]):\n",
    "            y.append(i)\n",
    "y = np.array(y)\n",
    "y = df['company']\n",
    "\n",
    "X = X\n",
    "\n",
    "# Double check\n",
    "print(X.shape,y.shape)\n",
    "print(\"DATA POINT-0:\",X[0,0:10],\"y =\",y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partion data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=4)\n",
    "\n",
    "# Check\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c1fc7",
   "metadata": {},
   "source": [
    "## SVM - Sigmoid Kernel Model and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f40bab2",
   "metadata": {},
   "source": [
    "## Model Results and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c1fc7",
   "metadata": {},
   "source": [
    "## SVM - Sigmoid Kernel Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize model\n",
    "\n",
    "C=500\n",
    "mykernel = 'sigmoid'\n",
    "\n",
    "model = SVC(C=C,kernel=mykernel)\n",
    "\n",
    "# Fit to training data\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# Predict on X_train\n",
    "y_train_pred = model.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ACCURACY\n",
    "\n",
    "# Training set\n",
    "print(\"Training set\")\n",
    "print(\"Accuracy: \", accuracy_score(y_train, y_train_pred) * 100) #accuracy score\n",
    "print(\"Number of mislabeled points: \", (y_train != y_train_pred).sum()) #mislabeled points\n",
    "\n",
    "\n",
    "# Test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test set\")\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_test_pred)*100) #accuracy score\n",
    "print(\"Number of mislabeled points: \", (y_test != y_test_pred).sum()) #mislabeled points\n",
    "\n",
    "# Plot\n",
    "model_accuracies = pd.DataFrame({'Set':['Training set','Test set'], 'Accuracy (%)': [accuracy_score(y_train, y_train_pred) * 100, accuracy_score(y_test, y_test_pred)*100]})\n",
    "sns.barplot(data=model_accuracies, x=\"Set\", y=\"Accuracy (%)\").set(title = 'Accuracy of '+str(mykernel)+' model for training vs test sets' )\n",
    "plt.savefig(\"../501-project-website/images/svm_\"+str(mykernel)+\"_tweets_accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX\n",
    "\n",
    "# Import confusion matrix library\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Create confusion matrix\n",
    "plot_confusion_matrix(model, X_test , y_test , cmap=\"Reds\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.title(\"SVM_\"+str(mykernel)+\"_Confusion Matrix\")\n",
    "plt.savefig(\"../501-project-website/images/SVM_\"+str(mykernel)+\"_record_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c1fc7",
   "metadata": {},
   "source": [
    "## SVM - Linear Kernel Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize model\n",
    "\n",
    "C=500\n",
    "mykernel = 'linear'\n",
    "\n",
    "model = SVC(C=C,kernel=mykernel)\n",
    "\n",
    "model\n",
    "\n",
    "# Fit to training data\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# Predict on X_train\n",
    "y_train_pred = model.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ACCURACY\n",
    "\n",
    "# Training set\n",
    "print(\"Training set\")\n",
    "print(\"Accuracy: \", accuracy_score(y_train, y_train_pred) * 100) #accuracy score\n",
    "print(\"Number of mislabeled points: \", (y_train != y_train_pred).sum()) #mislabeled points\n",
    "\n",
    "# Test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test set\")\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_test_pred)*100) #accuracy score\n",
    "print(\"Number of mislabeled points: \", (y_test != y_test_pred).sum()) #mislabeled points\n",
    "\n",
    "# Plot\n",
    "model_accuracies = pd.DataFrame({'Set':['Training set','Test set'], 'Accuracy (%)': [accuracy_score(y_train, y_train_pred) * 100, accuracy_score(y_test, y_test_pred)*100]})\n",
    "sns.barplot(data=model_accuracies, x=\"Set\", y=\"Accuracy (%)\").set(title = 'Accuracy of '+str(mykernel)+' model for training vs test sets' )\n",
    "plt.savefig(\"../501-project-website/images/svm_\"+str(mykernel)+\"_tweets_accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX\n",
    "\n",
    "# Import confusion matrix library\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Create confusion matrix\n",
    "plot_confusion_matrix(model, X_test , y_test , cmap=\"Reds\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.title(\"SVM_\"+str(mykernel)+\"_Confusion Matrix\")\n",
    "plt.savefig(\"../501-project-website/images/SVM_\"+str(mykernel)+\"_record_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c1fc7",
   "metadata": {},
   "source": [
    "## SVM - RBF Kernel Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize model\n",
    "\n",
    "C=500\n",
    "mykernel = 'rbf'\n",
    "\n",
    "model = SVC(C=C,kernel=mykernel)\n",
    "\n",
    "model\n",
    "\n",
    "# Fit to training data\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# Predict on X_train\n",
    "y_train_pred = model.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ACCURACY\n",
    "\n",
    "# Training set\n",
    "print(\"Training set\")\n",
    "print(\"Accuracy: \", accuracy_score(y_train, y_train_pred) * 100) #accuracy score\n",
    "print(\"Number of mislabeled points: \", (y_train != y_train_pred).sum()) #mislabeled points\n",
    "\n",
    "# Test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test set\")\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_test_pred)*100) #accuracy score\n",
    "print(\"Number of mislabeled points: \", (y_test != y_test_pred).sum()) #mislabeled points\n",
    "\n",
    "# Plot\n",
    "model_accuracies = pd.DataFrame({'Set':['Training set','Test set'], 'Accuracy (%)': [accuracy_score(y_train, y_train_pred) * 100, accuracy_score(y_test, y_test_pred)*100]})\n",
    "sns.barplot(data=model_accuracies, x=\"Set\", y=\"Accuracy (%)\").set(title = 'Accuracy of '+str(mykernel)+' model for training vs test sets' )\n",
    "plt.savefig(\"../501-project-website/images/svm_\"+str(mykernel)+\"_tweets_accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX\n",
    "\n",
    "# Import confusion matrix library\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Create confusion matrix\n",
    "plot_confusion_matrix(model, X_test , y_test , cmap=\"Reds\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.title(\"SVM_\"+str(mykernel)+\"_Confusion Matrix\")\n",
    "plt.savefig(\"../501-project-website/images/SVM_\"+str(mykernel)+\"_record_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c1fc7",
   "metadata": {},
   "source": [
    "## SVM - Polynomial Kernel Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize model\n",
    "\n",
    "C=500\n",
    "mykernel = 'poly'\n",
    "\n",
    "model = SVC(C=C,kernel=mykernel)\n",
    "\n",
    "model\n",
    "\n",
    "# Fit to training data\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# Predict on X_train\n",
    "y_train_pred = model.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ACCURACY\n",
    "\n",
    "# Training set\n",
    "print(\"Training set\")\n",
    "print(\"Accuracy: \", accuracy_score(y_train, y_train_pred) * 100) #accuracy score\n",
    "print(\"Number of mislabeled points: \", (y_train != y_train_pred).sum()) #mislabeled points\n",
    "\n",
    "# Test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test set\")\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_test_pred)*100) #accuracy score\n",
    "print(\"Number of mislabeled points: \", (y_test != y_test_pred).sum()) #mislabeled points\n",
    "\n",
    "# Plot\n",
    "model_accuracies = pd.DataFrame({'Set':['Training set','Test set'], 'Accuracy (%)': [accuracy_score(y_train, y_train_pred) * 100, accuracy_score(y_test, y_test_pred)*100]})\n",
    "sns.barplot(data=model_accuracies, x=\"Set\", y=\"Accuracy (%)\").set(title = 'Accuracy of '+str(mykernel)+' model for training vs test sets' )\n",
    "plt.savefig(\"../501-project-website/images/svm_\"+str(mykernel)+\"_tweets_accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX\n",
    "\n",
    "# Import confusion matrix library\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Create confusion matrix\n",
    "plot_confusion_matrix(model, X_test , y_test , cmap=\"Reds\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.title(\"SVM_\"+str(mykernel)+\"_Confusion Matrix\")\n",
    "plt.savefig(\"../501-project-website/images/SVM_\"+str(mykernel)+\"_record_confusion_matrix.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "15746aa1dcf7a2a78475ba9215d3f8835d2f92e9634eaaa8b18bbade37f57527"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
